{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e048aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ammaster10/Documents/Github/Year4/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# custom_objects downloading\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class RepeatChannels(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RepeatChannels, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Assuming the repeat operation repeats across channels\n",
    "        return K.repeat_elements(inputs, rep=3, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RepeatChannels, self).get_config()\n",
    "        return config\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = K.sum(y_true * y_pred)\n",
    "        union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient, a measure of overlap between two samples.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    return dice\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    # Binary Cross-Entropy\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    # Dice Loss\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
    "    # Combine both losses\n",
    "    return bce_loss + dice_loss\n",
    "\n",
    "# Load models with custom objects\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "custom_objects = {\n",
    "    'RepeatChannels': RepeatChannels,\n",
    "    'iou': iou,\n",
    "    'dice_coef': dice_coef,\n",
    "    'dice_loss': dice_loss,\n",
    "    'bce_dice_loss': bce_dice_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53858ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 340 images. Saving PNGs to '/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/predicted_masks_png' and NPYs to '/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/predicted_prob_maps_npy'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 340/340 [01:53<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! All predictions and probability maps saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# This is your existing noise function\n",
    "def preprocess_noise(image, method='median', kernel_size=3):\n",
    "    if kernel_size % 2 == 0 or kernel_size < 1:\n",
    "        raise ValueError(\"Kernel size must be an odd integer greater than 1.\")\n",
    "    if method == 'median':\n",
    "        return cv2.medianBlur(image, kernel_size)\n",
    "    raise ValueError(\"Unsupported denoising method.\")\n",
    "\n",
    "# --- THIS IS THE MODIFIED FUNCTION ---\n",
    "def run_inference_and_save_outputs(model, image_dir, coco_json_path, binary_mask_dir, prob_map_dir, target_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Runs model prediction and saves BOTH the binary mask and the probability map.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model.\n",
    "        image_dir (str): Base directory where image subfolders are located.\n",
    "        coco_json_path (str): Path to the COCO JSON file.\n",
    "        binary_mask_dir (str): Directory to save the final .png binary masks.\n",
    "        prob_map_dir (str): Directory to save the raw .npy probability maps.\n",
    "        target_size (tuple): The (Height, Width) for the model.\n",
    "    \"\"\"\n",
    "    # --- MODIFIED: Create both output directories ---\n",
    "    os.makedirs(binary_mask_dir, exist_ok=True)\n",
    "    os.makedirs(prob_map_dir, exist_ok=True)\n",
    "\n",
    "    coco = COCO(coco_json_path)\n",
    "    img_ids = coco.getImgIds()\n",
    "    print(f\"Found {len(img_ids)} images. Saving PNGs to '{binary_mask_dir}' and NPYs to '{prob_map_dir}'...\")\n",
    "\n",
    "    for img_id in tqdm(img_ids, desc=\"Generating predictions\"):\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        filename_from_json = img_info['file_name']\n",
    "        image_path = os.path.join(image_dir, filename_from_json)\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"\\nWarning: File not found, skipping -> {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # --- Preprocessing (unchanged) ---\n",
    "            img = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            img_uint8 = img_array.astype(np.uint8)\n",
    "            img_denoised = preprocess_noise(img_uint8, method='median', kernel_size=3)\n",
    "            img_normalized = img_denoised.astype(np.float32) / 255.0\n",
    "            model_input = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "            # --- PREDICTION AND SAVING ---\n",
    "            \n",
    "            # 1. Get the raw prediction. This is your probability map!\n",
    "            # Shape is (1, 512, 512, 1). Values are floats from 0.0 to 1.0.\n",
    "            raw_prediction = model.predict(model_input, verbose=0)\n",
    "            \n",
    "            # 2. Squeeze the extra dimensions to get a clean (512, 512) array.\n",
    "            # Safely squeeze from (1, H, W, 1) → (H, W)\n",
    "            if raw_prediction.shape == (1, 512, 512, 1):\n",
    "                probability_map = raw_prediction[0, :, :, 0]\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected prediction shape: {raw_prediction.shape}\")\n",
    "            \n",
    "\n",
    "            # 3. --- NEW: Save the probability map as a .npy file ---\n",
    "            base_name = os.path.splitext(os.path.basename(filename_from_json))[0]\n",
    "            prob_map_output_path = os.path.join(prob_map_dir, f\"{base_name}_prob_map.npy\")\n",
    "            np.save(prob_map_output_path, probability_map)\n",
    "\n",
    "            # 4. --- NOW create and save the binary mask like before ---\n",
    "            binary_mask = (probability_map > 0.5).astype(np.uint8) * 255\n",
    "            output_image = Image.fromarray(binary_mask)\n",
    "            \n",
    "            binary_mask_output_path = os.path.join(binary_mask_dir, f\"{base_name}_predicted_mask.png\")\n",
    "            output_image.save(binary_mask_output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename_from_json}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Done! All predictions and probability maps saved.\")\n",
    "\n",
    "# --- HOW TO RUN THE UPDATED SCRIPT ---\n",
    "if __name__ == '__main__':\n",
    "    base_dir = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder\"\n",
    "    \n",
    "    # Define all your paths\n",
    "    image_dir = os.path.join(base_dir, \"340_Test\")\n",
    "    coco_json_path = os.path.join(base_dir, \"subset_340.json\")\n",
    "    \n",
    "    # --- MODIFIED: Define separate output folders ---\n",
    "    binary_mask_output_dir = os.path.join(base_dir, \"predicted_masks_png\")\n",
    "    prob_map_output_dir = os.path.join(base_dir, \"predicted_prob_maps_npy\")\n",
    "    \n",
    "    MODEL_PATH = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Models/deeplabv3_plus_ultra_model_2025_02_10_01_37_48.keras\" # !!! IMPORTANT !!! - Update this path\n",
    "\n",
    "    try:\n",
    "        model = load_model(MODEL_PATH, compile=False, custom_objects=custom_objects)\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        # Dummy model for testing\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Conv2D\n",
    "        model = Sequential([Conv2D(1, (1,1), activation='sigmoid', input_shape=(512,512,1))])\n",
    "        print(\"Continuing with a dummy model.\")\n",
    "\n",
    "    run_inference_and_save_outputs(\n",
    "        model=model,\n",
    "        image_dir=image_dir,\n",
    "        coco_json_path=coco_json_path,\n",
    "        binary_mask_dir=binary_mask_output_dir, # Pass the new PNG dir\n",
    "        prob_map_dir=prob_map_output_dir,       # Pass the new NPY dir\n",
    "        target_size=(512, 512)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faff37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512) 1.4298232e-06 0.9999998\n"
     ]
    }
   ],
   "source": [
    "arr = np.load(\"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/predicted_prob_maps_npy/CNV-53264-13_prob_map.npy\")\n",
    "print(arr.shape, arr.min(), arr.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
