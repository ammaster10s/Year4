{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee33673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ammaster10/Documents/Github/Year4/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# custom_objects downloading\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class RepeatChannels(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RepeatChannels, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Assuming the repeat operation repeats across channels\n",
    "        return K.repeat_elements(inputs, rep=3, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RepeatChannels, self).get_config()\n",
    "        return config\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = K.sum(y_true * y_pred)\n",
    "        union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient, a measure of overlap between two samples.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    return dice\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    # Binary Cross-Entropy\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    # Dice Loss\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice_loss = 1 - (2. * intersection + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
    "    # Combine both losses\n",
    "    return bce_loss + dice_loss\n",
    "\n",
    "# Load models with custom objects\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "custom_objects = {\n",
    "    'RepeatChannels': RepeatChannels,\n",
    "    'iou': iou,\n",
    "    'dice_coef': dice_coef,\n",
    "    'dice_loss': dice_loss,\n",
    "    'bce_dice_loss': bce_dice_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a60cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLabV3 = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Models/deeplabv3_plus_ultra_model_2025_02_10_01_37_48.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb1c0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_noise(image, method='median', kernel_size=3):\n",
    "    if kernel_size % 2 == 0 or kernel_size < 1:\n",
    "        raise ValueError(\"Kernel size must be an odd integer greater than 1.\")\n",
    "\n",
    "    if method == 'gaussian':\n",
    "        # Apply Gaussian Blur\n",
    "        denoised = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    elif method == 'median':\n",
    "        # Apply Median Filter\n",
    "        denoised = cv2.medianBlur(image, kernel_size)\n",
    "    elif method == 'bilateral':\n",
    "        # Apply Bilateral Filter\n",
    "        denoised = cv2.bilateralFilter(image, kernel_size, 75, 75)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported denoising method. Use 'gaussian', 'median', or 'bilateral'.\")\n",
    "\n",
    "    return denoised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "481eb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_coco_json(json_file, image_dir):\n",
    "    \"\"\"\n",
    "    Parses the COCO JSON file and returns a dictionary of image masks.\n",
    "\n",
    "    Args:\n",
    "        json_file: Path to the COCO JSON file.\n",
    "        image_dir: Directory containing the images.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with image filenames as keys and corresponding masks as values.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pycocotools import mask as maskUtils\n",
    "    from PIL import ImageDraw\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    annotations = {}\n",
    "    image_data = {img['id']: img for img in coco_data['images']}\n",
    "\n",
    "    for ann in coco_data['annotations']:\n",
    "        img_info = image_data[ann['image_id']]\n",
    "        img_filename = img_info['file_name']\n",
    "        width, height = img_info['width'], img_info['height']\n",
    "\n",
    "        if 'segmentation' in ann:\n",
    "            segmentation = ann['segmentation']\n",
    "            mask = segmentation_to_mask(segmentation, width, height)\n",
    "            resized_mask = np.array(Image.fromarray(mask).resize((256, 256), Image.NEAREST))\n",
    "            annotations[img_filename] = resized_mask\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def segmentation_to_mask(segmentation, width, height):\n",
    "    \"\"\"\n",
    "    Converts COCO segmentation to a binary mask.\n",
    "\n",
    "    Args:\n",
    "        segmentation: COCO segmentation data (RLE or polygon).\n",
    "        width: Image width.\n",
    "        height: Image height.\n",
    "\n",
    "    Returns:\n",
    "        Binary mask as a numpy array.\n",
    "    \"\"\"\n",
    "    from pycocotools import mask as maskUtils\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    if isinstance(segmentation, list):  # Polygon format\n",
    "        mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        for polygon in segmentation:\n",
    "            poly = np.array(polygon).reshape((-1, 2))\n",
    "            img = Image.new('L', (width, height), 0)\n",
    "            ImageDraw.Draw(img).polygon([tuple(p) for p in poly], outline=1, fill=1)\n",
    "            mask = np.array(img, dtype=np.uint8)\n",
    "        return mask\n",
    "    elif isinstance(segmentation, dict):  # RLE format\n",
    "        rle = maskUtils.frPyObjects(segmentation, height, width)\n",
    "        mask = maskUtils.decode(rle)\n",
    "        return mask\n",
    "    return np.zeros((height, width), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f010b72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from: /Users/ammaster10/Documents/Github/Year4/CNVresearch/Models/deeplabv3_plus_ultra_model_2025_02_10_01_37_48.keras\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the DeepLabV3+ model with custom objects\n",
    "model = load_model(DeepLabV3, custom_objects=custom_objects)\n",
    "\n",
    "# Print model summary to verify it loaded correctly\n",
    "print(f\"Model loaded successfully from: {DeepLabV3}\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aa01dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  # You might need to run: pip install opencv-python\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model # To load your model\n",
    "# The following imports are for the COCO functions, which are included but not used in the main loop\n",
    "import json\n",
    "from pycocotools import mask as maskUtils\n",
    "from PIL import ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def run_inference_and_save_predictions(model, image_dir, coco_json_path, output_dir, target_size=(256, 256)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    coco = COCO(coco_json_path)\n",
    "    img_ids = coco.getImgIds()\n",
    "    print(f\"Found {len(img_ids)} image entries in the JSON. Processing with target_size={target_size}...\")\n",
    "\n",
    "    for img_id in tqdm(img_ids, desc=\"Predicting masks\"):\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        filename = img_info['file_name']\n",
    "\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"\\nWarning: File not found, skipping -> {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # This will now use the corrected target_size (e.g., 512x512)\n",
    "            img = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "            \n",
    "            img_array = img_to_array(img)\n",
    "            img_uint8 = img_array.astype(np.uint8)\n",
    "            img_denoised = preprocess_noise(img_uint8, method='median', kernel_size=3)\n",
    "            img_normalized = img_denoised.astype(np.float32) / 255.0\n",
    "            model_input = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "            predicted_mask = model.predict(model_input, verbose=0)[0]\n",
    "            binary_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "            output_image_array = np.squeeze(binary_mask) * 255\n",
    "            output_image = Image.fromarray(output_image_array, mode='L')\n",
    "            \n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            output_path = os.path.join(output_dir, f\"{base_name}_predicted_mask.png\")\n",
    "            output_image.save(output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {filename}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Done! All predicted masks saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4459f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 340 image entries in the JSON. Processing with target_size=(512, 512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting masks:   0%|          | 0/340 [00:00<?, ?it/s]2025-08-16 20:42:04.916741: I external/local_xla/xla/service/service.cc:163] XLA service 0x31390d680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-16 20:42:04.916760: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Host, Default Version\n",
      "2025-08-16 20:42:05.001688: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755351725.743988 1102705 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/var/folders/q3/rnsm0fg975ld64pvb5fc5dmm0000gn/T/ipykernel_79864/1375145498.py:43: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  output_image = Image.fromarray(output_image_array, mode='L')\n",
      "Predicting masks: 100%|██████████| 340/340 [04:45<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! All predicted masks saved to: /Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/GVF_Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/340_Test\"\n",
    "coco_json_path = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/subset_340.json\"\n",
    "output_dir = \"/Users/ammaster10/Documents/Github/Year4/CNVresearch/Validation/340_Folder/GVF_Ready\"\n",
    "\n",
    "run_inference_and_save_predictions(model, image_dir,coco_json_path=coco_json_path, output_dir=output_dir, target_size=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, img_as_float\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import find_boundaries\n",
    "from morphsnakes import morphsnakes\n",
    "\n",
    "# 1. Load original grayscale image and corresponding predicted mask\n",
    "original = img_as_float(io.imread(\"OCT_image.png\", as_gray=True))  # Your original OCT slice\n",
    "mask = io.imread(\"DeepLabV3pp_mask.png\", as_gray=True) > 0.5       # Binary mask\n",
    "\n",
    "# 2. Smooth original image (optional but helps stability)\n",
    "smoothed = gaussian(original, sigma=1.0)\n",
    "\n",
    "# 3. Initialize the level set (phi) from the mask\n",
    "init_ls = mask.astype(float)\n",
    "\n",
    "# 4. Apply Morphological GVF Snake\n",
    "mgvf = morphsnakes.MorphGAC(\n",
    "    smoothed,\n",
    "    smoothing=2,\n",
    "    threshold=0.3,\n",
    "    balloon=-1\n",
    ")\n",
    "\n",
    "mgvf.levelset = init_ls\n",
    "for i in range(100):  # You can tune iterations\n",
    "    mgvf.step()\n",
    "\n",
    "# 5. Final mask\n",
    "refined_mask = mgvf.levelset > 0.5\n",
    "\n",
    "# 6. Visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original, cmap='gray')\n",
    "plt.title(\"Original\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(\"Initial Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(refined_mask, cmap='gray')\n",
    "plt.title(\"GVF Refined Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
